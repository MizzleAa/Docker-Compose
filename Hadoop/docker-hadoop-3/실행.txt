https://wroni.tistory.com/25?category=992371 따라하기

su - 
apt-get update
apt-get install sudo
sudo apt-get install nano
sudo apt-get install wget

wget http://mirror.navercorp.com/apache/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz

sudo tar -xvf hadoop-3.2.3.tar.gz -C /opt/
rm hadoop-3.2.3.tar.gz
cd /opt
sudo mv hadoop-3.2.3 hadoop
sudo chown pi:pi -R /opt/hadoop

cd ~
nano .bashrc

```
export JAVA_HOME=$(readlink –f /usr/bin/java | sed "s:bin/java::")
export HADOOP_HOME=/opt/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

nano /opt/hadoop/etc/hadoop/hadoop-env.sh
```
export JAVA_HOME=$(readlink -f /usr/bin/java | sed "s:bin/java::")
```

source .bashrc
hadoop version

### console message
Hadoop 3.2.3
Source code repository https://github.com/apache/hadoop -r abe5358143720085498613d399be3bbf01e0f131
Compiled by ubuntu on 2022-03-20T01:18Z
Compiled with protoc 2.5.0
From source with checksum 39bb14faec14b3aa25388a6d7c345fe8
This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-3.2.3.jar
###

wget http://mirror.navercorp.com/apache/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz

sudo tar –xvf spark-3.2.1-bin-hadoop3.2.tgz –C /opt/
rm spark-3.2.1-bin-hadoop3.2.tgz
cd /opt
sudo mv spark-3.2.1-bin-hadoop3.2 spark


cd ~
nano .bashrc

```
export SPARK_HOME=/opt/spark # 추가
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SPARK_HOME/bin # SPARK_HOME 추가
```

source .bashrc
spark-shell --version
###console
###

sudo nano /opt/hadoop/etc/hadoop/core-site.xml

```
<configuration>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://nn:9000</value>
	</property>
</configuration>

```

sudo nano /opt/hadoop/etc/hadoop/hdfs-site.xml

```
<configuration>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file:///opt/hadoop_tmp/hdfs/datanode</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file:///opt/hadoop_tmp/hdfs/namenode</value>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
</configuration>
```

sudo mkdir –p /opt/hadoop_tmp/hdfs/datanode
sudo mkdir –p /opt/hadoop_tmp/hdfs/namenode
#sudo chown pi:pi –R /opt/hadoop_tmp

sudo nano /opt/hadoop/etc/hadoop/mapred-site.xml
```
<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
</configuration>
```

sudo nano /opt/hadoop/etc/hadoop/yarn-site.xml
```
<configuration>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<property>
		<name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
		<value>org.apache.hadoop.mapred.ShuffleHandler</value>
	</property>
</configuration>
```

hdfs namenode -format -force

